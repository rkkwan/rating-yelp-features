{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Reviews to Sentences\n",
    "\n",
    "The input of this notebook is a dataframe of reviews that mention one menu item. The output is a dataframe of the individual sentences that mention that menu item. As an example, I am using `onion soup` and `eggs benedict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/odo/backends/pandas.py:94: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "  @convert.register((pd.Timestamp, pd.Timedelta), (pd.tslib.NaTType, type(None)))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# Display full content of column\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import spacy\n",
    "import textblob\n",
    "\n",
    "# For reading from Postgres\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# For pickling\n",
    "import pickle\n",
    "\n",
    "# For tracking progress\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# For reading and writing to postgres\n",
    "from odo import odo\n",
    "\n",
    "# For detecting language of document\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory \n",
    "\n",
    "# for consistent results\n",
    "DetectorFactory.seed = 42 \n",
    "\n",
    "import nltk\n",
    "\n",
    "# The NLP workhorse in Python is Natural Language Toolkit (NLTK)\n",
    "# Tokenizing, lemmatizing\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "# Preprocessing packages used in class\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "# For loading secret environment variables, e.g. postgres username and password\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Postgres table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "CREATE TABLE reviews (\n",
    "    date          date, \n",
    "    stars         integer NOT NULL,\n",
    "    text          varchar(5000), \n",
    "    review_id     varchar(22),\n",
    "    business_id   varchar(22),\n",
    "    business_name varchar(64)  \n",
    ");\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV file to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_directory     = os.path.join('..', 'data', 'raw')\n",
    "interim_data_directory = os.path.join('..', 'data', 'interim')\n",
    "\n",
    "review_filepath            = os.path.join(raw_data_directory, 'yelp_academic_dataset_review.csv')\n",
    "business_filepath          = os.path.join(raw_data_directory, 'yelp_academic_dataset_business.csv')\n",
    "restaurant_review_filepath = os.path.join(interim_data_directory, 'restaurant_review.csv')\n",
    "restaurant_filepath        = os.path.join(interim_data_directory, 'restaurant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f'''\n",
    "COPY reviews(date, stars, text, review_id, business_id, business_name)\n",
    "FROM '{restaurant_review_filepath}' DELIMITER ',' CSV HEADER;\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find .env\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# Load entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "public_ip = os.environ.get(\"PUBLIC_IP\")\n",
    "username = os.environ.get(\"USERNAME\")\n",
    "password = os.environ.get(\"PASSWORD\")\n",
    "port = os.environ.get(\"PORT\")\n",
    "\n",
    "# Construct database URL from environment variables\n",
    "uri = f'postgresql://{username}:{password}@{public_ip}:{port}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data \n",
    "#### Option 1: Local Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_ip = 'localhost'\n",
    "username = 'postgres'\n",
    "password = 'password'\n",
    "port = '5432'\n",
    "database = 'yelp'\n",
    "\n",
    "# Construct database URL from environment variables\n",
    "uri = f'postgresql://{username}:{password}@{public_ip}:{port}/{database}'\n",
    "\n",
    "# uri = 'postgresql://pos:lilo8catfood@127.0.0.0:5432'\n",
    "# reviews = odo(uri+'::reviews', pd.DataFrame)\n",
    "\n",
    "# Connection to Postgres database\n",
    "engine = create_engine(uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.34 ms, sys: 3.81 ms, total: 10.1 ms\n",
      "Wall time: 6.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SQL = '''\n",
    "SELECT r.*\n",
    "FROM reviews AS r\n",
    "WHERE r.business_name ILIKE 'Mon Ami Gabi'\n",
    "  AND r.text LIKE '%%onion soup%%'\n",
    "'''\n",
    "\n",
    "onion_soup_reviews = pd.read_sql(SQL, con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(674, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_name</th>\n",
       "      <th>text_tsv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>2</td>\n",
       "      <td>Other than being right across the Fountains of...</td>\n",
       "      <td>uczUlWIWuO-KzoUiLhICNw</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-07-11</td>\n",
       "      <td>5</td>\n",
       "      <td>This review is long overdue!   I have been eat...</td>\n",
       "      <td>l0Lm7Dx69s6aH7a-5dwKDg</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>3</td>\n",
       "      <td>French onion soup was watery with little taste...</td>\n",
       "      <td>185E0cpQpDRUO4JRGu3fXQ</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-04</td>\n",
       "      <td>4</td>\n",
       "      <td>Charming resturant that looks like it would be...</td>\n",
       "      <td>nth_q-GqOy_Ly8sxsREIwA</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-30</td>\n",
       "      <td>5</td>\n",
       "      <td>Brunch with the family was out of this world. ...</td>\n",
       "      <td>EL1LCOPj40kQjLweA81Uww</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  stars                                               text  \\\n",
       "0  2015-02-10      2  Other than being right across the Fountains of...   \n",
       "1  2010-07-11      5  This review is long overdue!   I have been eat...   \n",
       "2  2017-04-24      3  French onion soup was watery with little taste...   \n",
       "3  2010-12-04      4  Charming resturant that looks like it would be...   \n",
       "4  2014-12-30      5  Brunch with the family was out of this world. ...   \n",
       "\n",
       "                review_id             business_id business_name text_tsv  \n",
       "0  uczUlWIWuO-KzoUiLhICNw  4JNXUYY8wbaaDmk3BPzlWw  Mon Ami Gabi     None  \n",
       "1  l0Lm7Dx69s6aH7a-5dwKDg  4JNXUYY8wbaaDmk3BPzlWw  Mon Ami Gabi     None  \n",
       "2  185E0cpQpDRUO4JRGu3fXQ  4JNXUYY8wbaaDmk3BPzlWw  Mon Ami Gabi     None  \n",
       "3  nth_q-GqOy_Ly8sxsREIwA  4JNXUYY8wbaaDmk3BPzlWw  Mon Ami Gabi     None  \n",
       "4  EL1LCOPj40kQjLweA81Uww  4JNXUYY8wbaaDmk3BPzlWw  Mon Ami Gabi     None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Load data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(868, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_reviews = pd.read_csv('../data/interim/onion_soup_reviews.csv')\n",
    "onion_soup_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eggs_benedict_reviews = pd.read_csv('../data/interim/eggs_benedict_reviews.csv')\n",
    "eggs_benedict_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = pickle.load( open( \"../data/interim/mon_ami_gabi_menu.pk\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>variations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>onion_soup_au_gratin</td>\n",
       "      <td>onion soup au gratin</td>\n",
       "      <td>[french onion soup, onion soup, french onion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>steamed_artichoke</td>\n",
       "      <td>steamed artichoke</td>\n",
       "      <td>[steamed artichoke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smoked_salmon</td>\n",
       "      <td>smoked salmon</td>\n",
       "      <td>[smoked salmon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baked_goat_cheese</td>\n",
       "      <td>baked goat cheese</td>\n",
       "      <td>[goat cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duck_confit</td>\n",
       "      <td>duck confit</td>\n",
       "      <td>[duck confit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                  name  \\\n",
       "0  onion_soup_au_gratin  onion soup au gratin   \n",
       "1     steamed_artichoke     steamed artichoke   \n",
       "2         smoked_salmon         smoked salmon   \n",
       "3     baked_goat_cheese     baked goat cheese   \n",
       "4           duck_confit           duck confit   \n",
       "\n",
       "                                          variations  \n",
       "0  [french onion soup, onion soup, french onion, ...  \n",
       "1                                [steamed artichoke]  \n",
       "2                                    [smoked salmon]  \n",
       "3                                      [goat cheese]  \n",
       "4                                      [duck confit]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows that are not English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_english_reviews(df):\n",
    "    language = df['text'].apply(detect)\n",
    "                  \n",
    "    return df.drop(df[language != 'en'].index, axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867\n",
      "CPU times: user 3.99 s, sys: 113 ms, total: 4.1 s\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "onion_soup_reviews = get_english_reviews(onion_soup_reviews)\n",
    "print(onion_soup_reviews.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n",
      "CPU times: user 2.74 s, sys: 82.1 ms, total: 2.82 s\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eggs_benedict_reviews = get_english_reviews(eggs_benedict_reviews)\n",
    "print(eggs_benedict_reviews.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize & Lemmatize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Penn Part of Speech Tags](https://cs.nyu.edu/grishman/jet/guide/PennPOS.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(sentence):\n",
    "    # Tokenize doc\n",
    "    tokens = word_tokenize(sentence)\n",
    "    \n",
    "    # Tag sentences\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "    # Named entity chunker\n",
    "    ne_chunked_tokens = ne_chunk(tagged_tokens, binary = True)\n",
    "#     return ne_chunked_tokens\n",
    "    # Extract all named entities\n",
    "    named_entities = []\n",
    "    \n",
    "    for tagged_tree in ne_chunked_tokens:\n",
    "#         print(tagged_tree)\n",
    "        if hasattr(tagged_tree, 'label'):\n",
    "            entity_name = ' '.join(c[0] for c in tagged_tree.leaves())\n",
    "            entity_type = tagged_tree.label() # category\n",
    "            named_entities.append((entity_name, entity_type))\n",
    "    \n",
    "    return named_entities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "processed_review = preprocess2(onion_soup_reviews['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bellagio', 'NE'),\n",
       " ('Bordelaise Steak Frites', 'NE'),\n",
       " ('Chicken', 'NE'),\n",
       " ('Mushroom Crepe', 'NE'),\n",
       " ('Seafood Crepe', 'NE'),\n",
       " ('Eggs Benedict', 'NE'),\n",
       " ('Canadian', 'NE'),\n",
       " ('Steak', 'NE')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK's tokenizer fails to detect onion soup as an entity, so I will continue using a less programmatic approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate each review document into individual sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(superlist): \n",
    "    '''\n",
    "    Arguments: \n",
    "    superlist : A list of list of strings.\n",
    "\n",
    "    Requirements: \n",
    "    Each element in superlist must be a list.\n",
    "    \n",
    "    Return:\n",
    "    A flattened list of strings.\n",
    "\n",
    "    ex: \n",
    "    flatten([['a'], ['b', 'c'], ['d', 'e', 'f']])\n",
    "    >> ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "    '''    \n",
    "    return [item \\\n",
    "            for sublist in superlist \\\n",
    "            for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(doc, menu_item):\n",
    "    '''\n",
    "    Arguments: \n",
    "    doc : pd.Series of reviews\n",
    "    menu_item : pd.Series of a menu item. example: menu.iloc[0] = \"onion_soup_au_gratin\"\n",
    "    \n",
    "    Splits a string into individual sentences and\n",
    "    selects only the sentences that contain the search term\n",
    "    \n",
    "    Return:\n",
    "    DataFrame of sentences with their target\n",
    "    '''\n",
    "    sentences = doc.apply(lambda text : text.split('.'))\n",
    "#     df['sentences'] = df['sentences'].apply(lambda sentences : [s for s in sentences])\n",
    "    sentences = flatten(sentences)\n",
    "    \n",
    "    tagged_sentences = []\n",
    "    sentences_tags = []\n",
    "    \n",
    "    n_sentences = len(sentences)\n",
    "    \n",
    "    for i,s in enumerate(sentences):\n",
    "        s = s.lower()\n",
    "        \n",
    "        if (i+1)%1000==0:\n",
    "            clear_output(wait = True)\n",
    "            print(f'Finding tags in {i+1}/{n_sentences} sentences')\n",
    "\n",
    "        tags = []\n",
    "        for i,row in menu.iterrows():\n",
    "            for variation in row['variations']:\n",
    "                if variation in s:\n",
    "                    # print(row['entity'], '\\t', variation)\n",
    "                    tags.append(row['name'])\n",
    "                    break\n",
    "        sentences_tags.append(', '.join(tags))\n",
    "    \n",
    "    return pd.DataFrame(list(zip(sentences, sentences_tags)), columns = ['text', 'tags'])\n",
    "#     return pd.DataFrame([{'text' : s, 'target' : term} for s in sentences])    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all sentences that mention \"onion soup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tags in 10000/10720 sentences\n",
      "CPU times: user 45.2 s, sys: 95.1 ms, total: 45.3 s\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "onion_soup_sentences = get_sentences(onion_soup_reviews['text'], menu[menu['id'] == 'onion_soup_au_gratin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1007, 2)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_sentences = onion_soup_sentences[onion_soup_sentences['tags'].str.contains('onion soup au gratin')]\n",
    "onion_soup_sentences.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our table ordered Bordelaise Steak Frites (...</td>\n",
       "      <td>onion soup au gratin, scallops gratinees, bord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The steak frites and onion soup were the be...</td>\n",
       "      <td>onion soup au gratin, prime steak frites, frites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Onion soup was also a nice, big portion, but ...</td>\n",
       "      <td>onion soup au gratin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>French onion soup was watery with little taste</td>\n",
       "      <td>onion soup au gratin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>We ate almost everything on the menu - altho...</td>\n",
       "      <td>onion soup au gratin, baked goat cheese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "2      Our table ordered Bordelaise Steak Frites (...   \n",
       "3      The steak frites and onion soup were the be...   \n",
       "5    Onion soup was also a nice, big portion, but ...   \n",
       "12     French onion soup was watery with little taste   \n",
       "20    We ate almost everything on the menu - altho...   \n",
       "\n",
       "                                                 tags  \n",
       "2   onion soup au gratin, scallops gratinees, bord...  \n",
       "3    onion soup au gratin, prime steak frites, frites  \n",
       "5                                onion soup au gratin  \n",
       "12                               onion soup au gratin  \n",
       "20            onion soup au gratin, baked goat cheese  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_soup_sentences.to_csv('../data/interim/onion_soup_sentences.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all sentences that mention \"eggs benedict\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tags in 6000/6464 sentences\n"
     ]
    }
   ],
   "source": [
    "eggs_benedict_sentences = get_sentences(eggs_benedict_reviews['text'], menu[menu['id'] == 'classic_eggs_benedict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 2)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eggs_benedict_sentences = eggs_benedict_sentences[eggs_benedict_sentences['tags'].str.contains('classic eggs benedict')]\n",
    "eggs_benedict_sentences.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eggs Benedict for me was fab and some other g...</td>\n",
       "      <td>classic eggs benedict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The French toast and eggs Benedict with duck ...</td>\n",
       "      <td>classic eggs benedict, french toast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Our table ordered Bordelaise Steak Frites (...</td>\n",
       "      <td>onion soup au gratin, scallops gratinees, bord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Eggs benedict here is definitely not a stand-...</td>\n",
       "      <td>classic eggs benedict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The Salmon Eggs Benedict is scrumptious, and ...</td>\n",
       "      <td>salmon, classic eggs benedict, waffle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "1    Eggs Benedict for me was fab and some other g...   \n",
       "5    The French toast and eggs Benedict with duck ...   \n",
       "11     Our table ordered Bordelaise Steak Frites (...   \n",
       "18   Eggs benedict here is definitely not a stand-...   \n",
       "27   The Salmon Eggs Benedict is scrumptious, and ...   \n",
       "\n",
       "                                                 tags  \n",
       "1                               classic eggs benedict  \n",
       "5                 classic eggs benedict, french toast  \n",
       "11  onion soup au gratin, scallops gratinees, bord...  \n",
       "18                              classic eggs benedict  \n",
       "27              salmon, classic eggs benedict, waffle  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eggs_benedict_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs_benedict_sentences.to_csv('../data/interim/eggs_benedict_sentences.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
