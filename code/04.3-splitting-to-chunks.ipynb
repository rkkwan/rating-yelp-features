{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Sentences to Chunks\n",
    "\n",
    "The input to this notebook is a dataframe of sentences that mention one menu item. The output is a list of sentence chunks that mention that menu item. `get_chunks()` extracts sentence fragments from a sentence. The size of sentence chunks can be customized changing the arguments `n_before` and `n_after`.\n",
    "\n",
    "For example,   \n",
    "```s = 'The French onion soup is out of this world and the skate fish entree is terrific'\n",
    "get_chunks(s, 'onion soup', 7, 7)```  \n",
    "becomes  \n",
    "`'the french onion soup is out of this world and'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pickle\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_soup_sentences = pd.read_csv('../data/interim/onion_soup_sentences.csv')\n",
    "menu = pickle.load( open( \"../data/interim/mon_ami_gabi_menu.pk\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our table ordered Bordelaise Steak Frites (...</td>\n",
       "      <td>onion soup au gratin, scallops gratinees, bord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The steak frites and onion soup were the be...</td>\n",
       "      <td>onion soup au gratin, prime steak frites, frites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Onion soup was also a nice, big portion, but ...</td>\n",
       "      <td>onion soup au gratin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French onion soup was watery with little taste</td>\n",
       "      <td>onion soup au gratin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We ate almost everything on the menu - altho...</td>\n",
       "      <td>onion soup au gratin, baked goat cheese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0     Our table ordered Bordelaise Steak Frites (...   \n",
       "1     The steak frites and onion soup were the be...   \n",
       "2   Onion soup was also a nice, big portion, but ...   \n",
       "3     French onion soup was watery with little taste   \n",
       "4    We ate almost everything on the menu - altho...   \n",
       "\n",
       "                                                tags  \n",
       "0  onion soup au gratin, scallops gratinees, bord...  \n",
       "1   onion soup au gratin, prime steak frites, frites  \n",
       "2                               onion soup au gratin  \n",
       "3                               onion soup au gratin  \n",
       "4            onion soup au gratin, baked goat cheese  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1007, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>variations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>onion_soup_au_gratin</td>\n",
       "      <td>onion soup au gratin</td>\n",
       "      <td>[french onion soup, onion soup, french onion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>steamed_artichoke</td>\n",
       "      <td>steamed artichoke</td>\n",
       "      <td>[steamed artichoke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smoked_salmon</td>\n",
       "      <td>smoked salmon</td>\n",
       "      <td>[smoked salmon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baked_goat_cheese</td>\n",
       "      <td>baked goat cheese</td>\n",
       "      <td>[goat cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duck_confit</td>\n",
       "      <td>duck confit</td>\n",
       "      <td>[duck confit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                  name  \\\n",
       "0  onion_soup_au_gratin  onion soup au gratin   \n",
       "1     steamed_artichoke     steamed artichoke   \n",
       "2         smoked_salmon         smoked salmon   \n",
       "3     baked_goat_cheese     baked goat cheese   \n",
       "4           duck_confit           duck confit   \n",
       "\n",
       "                                          variations  \n",
       "0  [french onion soup, onion soup, french onion, ...  \n",
       "1                                [steamed artichoke]  \n",
       "2                                    [smoked salmon]  \n",
       "3                                      [goat cheese]  \n",
       "4                                      [duck confit]  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_term(word_list, term):\n",
    "    '''\n",
    "    Arguments:\n",
    "    word_list : List of words or a string\n",
    "    term      : List or string of words to search for\n",
    "    \n",
    "    Finds the start and end indices of a search term in a string.\n",
    "    `start` is the index of the first character in `term` in word_list,\n",
    "    `end` is the index of the last character in `term` in word_list.    \n",
    "    \n",
    "    Return:\n",
    "    results : List of tuples (start, end)\n",
    "    '''    \n",
    "    # Check if word_list is a string or list\n",
    "    if type(word_list) is str:\n",
    "        word_list = word_list.lower().split()\n",
    "    elif type(word_list) is not list:\n",
    "        print('Error: word_list must be a list or string.')\n",
    "        return None\n",
    "\n",
    "    # Check if term is a string or list    \n",
    "    if type(term) is str:\n",
    "        term = term.lower().split()\n",
    "    elif type(term) is not list:\n",
    "        print('Error: term must be a list or string.')\n",
    "        return None\n",
    "\n",
    "    results = []\n",
    "    term_length = len(term)\n",
    "\n",
    "    # Find indices of term[0] in sentence\n",
    "    for ind in (i for i, word in enumerate(word_list) if word == term[0]):\n",
    "        # Check if rest of the term matches\n",
    "        if word_list[ind:ind + term_length] == term:\n",
    "            results.append((ind, ind+term_length-1))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (8, 9)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test that find_term works\n",
    "find_term('The onion soup is at index (1,2). The onion soup is also at index (8,9).', 'onion soup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(word_list, term, n_before = 5, n_after = 5):\n",
    "    '''\n",
    "    Arguments:\n",
    "    word_list : List or string of words\n",
    "    term      : List or string of words to search for\n",
    "    before    : Number of characters to span before term\n",
    "    after     : Number of characters to span after term   \n",
    "    \n",
    "    Gets a list of sentence fragments containing term in word_list\n",
    "    Each sentence fragment spans n_before characters to the left\n",
    "    or until the start of the word_list\n",
    "    and n_after characters to the right \n",
    "    or until the end of the word_list\n",
    "    \n",
    "    Return:\n",
    "    chunks : List of chunks\n",
    "    \n",
    "    '''\n",
    "    # Check if word_list is a string or list\n",
    "    if type(word_list) is str:\n",
    "        word_list = word_list.lower().split()\n",
    "    elif type(word_list) is not list:\n",
    "        print('Error: word_list must be a list or string.')\n",
    "        return None\n",
    "    \n",
    "    # Check if term is a string or list    \n",
    "    if type(term) is str:\n",
    "        term = term.lower().split()\n",
    "    elif type(term) is not list:\n",
    "        print('Error: term must be a list or string.')\n",
    "        return None    \n",
    "    \n",
    "    indices = find_term(word_list, term)\n",
    "    chunks = []\n",
    "\n",
    "    for start, end in indices:\n",
    "        before = n_before\n",
    "        after = n_after\n",
    "        \n",
    "        # Check if start index is near the beginning of the word_list\n",
    "        if start < n_before:\n",
    "            before = start\n",
    "        # Check if end index is near the end of the word_list\n",
    "        if end > len(word_list) - n_after:\n",
    "            after = len(word_list) - end\n",
    "            \n",
    "        chunks.append(' '.join(word_list[start-before : end+after+1]))\n",
    "        \n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my children do not like onion soup']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test get_chunks() with punctuation\n",
    "test = 'I got the the onion soup, which was great my wife also enjoyed the onion soup, my children do not like onion soup'\n",
    "get_chunks(test, 'onion soup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input string must be lemmatized before running `get_chunks()`, or it will fail to extract terms with punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i got the the onion soup which was great my wife',\n",
       " 'my wife also enjoyed the onion soup my children do not like',\n",
       " 'my children do not like onion soup']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test get_chunks() without punctuation\n",
    "test = 'I got the the onion soup which was great my wife also enjoyed the onion soup my children do not like onion soup'\n",
    "get_chunks(test, 'onion soup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(superlist): \n",
    "    '''\n",
    "    Arguments: \n",
    "    superlist : A list of list of strings.\n",
    "\n",
    "    Requirements: \n",
    "    Each element in superlist must be a list.\n",
    "    \n",
    "    Return:\n",
    "    A flattened list of strings.\n",
    "\n",
    "    ex: \n",
    "    flatten([['a'], ['b', 'c'], ['d', 'e', 'f']])\n",
    "    >> ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "    '''    \n",
    "    return [item \\\n",
    "            for sublist in superlist \\\n",
    "            for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onion_soup_chunks = []\n",
    "onion_soup_chunks = onion_soup_sentences['text'].apply(lambda row: get_chunks(remove_punctuation(row), 'onion soup', 7, 7))\n",
    "onion_soup_chunks = pd.Series(flatten(onion_soup_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005,)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    crepe with scallops shrimp peas and cream onio...\n",
       "1    the steak frites and onion soup were the best ...\n",
       "2           onion soup was also a nice big portion but\n",
       "3       french onion soup was watery with little taste\n",
       "4    everything on the menu although their french o...\n",
       "dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(onion_soup_chunks, columns=['text']).to_csv('../data/interim/onion_soup_chunks.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
