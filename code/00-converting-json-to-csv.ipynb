{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file extracted from the Yelp dataset `yelp_academic.tar` file is a typeless file `yelp_dataset`. This is actually another tar file, so manually add the `.tar` extension and extract again to get to the true data files. \n",
    "\n",
    "The Yelp Dataset is a series of JSON files. Before performing data analysis, convert the JSON files to CSVs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import simplejson as sjson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON and CSV File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['business', 'checkin', 'photo', 'review', 'tip', 'user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_paths = {cat : '../data/json/yelp_academic_dataset_{}.json'.format(cat) \n",
    "                   for cat in categories}\n",
    "\n",
    "csv_file_paths = {cat : '../data/csv/yelp_academic_dataset_{}.csv'.format(cat) \n",
    "                   for cat in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': '../data/json/yelp_academic_dataset_business.json',\n",
       " 'checkin': '../data/json/yelp_academic_dataset_checkin.json',\n",
       " 'photo': '../data/json/yelp_academic_dataset_photo.json',\n",
       " 'review': '../data/json/yelp_academic_dataset_review.json',\n",
       " 'tip': '../data/json/yelp_academic_dataset_tip.json',\n",
       " 'user': '../data/json/yelp_academic_dataset_user.json'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': '../data/csv/yelp_academic_dataset_business.csv',\n",
       " 'checkin': '../data/csv/yelp_academic_dataset_checkin.csv',\n",
       " 'photo': '../data/csv/yelp_academic_dataset_photo.csv',\n",
       " 'review': '../data/csv/yelp_academic_dataset_review.csv',\n",
       " 'tip': '../data/csv/yelp_academic_dataset_tip.csv',\n",
       " 'user': '../data/csv/yelp_academic_dataset_user.csv'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in JSON, Write out to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_write_file(json_file_path, csv_file_path, column_names):\n",
    "    '''\n",
    "    Read in JSON file\n",
    "    write out as CSV file\n",
    "    with column_names as header\n",
    "    '''\n",
    "    \n",
    "    with open(csv_file_path, 'w+') as f_out:\n",
    "        csv_file = csv.writer(f_out)\n",
    "        csv_file.writerow(list(column_names))\n",
    "        with open(json_file_path) as f_in:\n",
    "            for line in f_in:\n",
    "                d = sjson.loads(line)\n",
    "                csv_file.writerow(get_row(d, column_names))\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Superset of Column Names\n",
    "The superset is the set of all possible column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superset_of_column_names(json_file_path):\n",
    "    '''\n",
    "    Arguments:\n",
    "    json_file_path : string pathname of a JSON file\n",
    "    \n",
    "    Extracts the unique column names (keys) of a JSON file\n",
    "    \n",
    "    Return:\n",
    "    column_names : Set of all column names (keys) of a JSON file\n",
    "    \n",
    "    Example:\n",
    "    json_file = {'a' : {'b' : 1, 'c' : 2}}\n",
    "    column_names = {'a.b', 'a.c'}\n",
    "    '''\n",
    "    \n",
    "    column_names = set()\n",
    "    with open(json_file_path) as f_in:\n",
    "        for line in f_in:\n",
    "            d = sjson.loads(line)\n",
    "            column_names.update(set(get_column_names(d)))\n",
    "\n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address',\n",
       " 'attributes',\n",
       " 'attributes.AcceptsInsurance',\n",
       " 'attributes.AgesAllowed',\n",
       " 'attributes.Alcohol',\n",
       " 'attributes.Ambience',\n",
       " 'attributes.BYOB',\n",
       " 'attributes.BYOBCorkage',\n",
       " 'attributes.BestNights',\n",
       " 'attributes.BikeParking',\n",
       " 'attributes.BusinessAcceptsBitcoin',\n",
       " 'attributes.BusinessAcceptsCreditCards',\n",
       " 'attributes.BusinessParking',\n",
       " 'attributes.ByAppointmentOnly',\n",
       " 'attributes.Caters',\n",
       " 'attributes.CoatCheck',\n",
       " 'attributes.Corkage',\n",
       " 'attributes.DietaryRestrictions',\n",
       " 'attributes.DogsAllowed',\n",
       " 'attributes.DriveThru',\n",
       " 'attributes.GoodForDancing',\n",
       " 'attributes.GoodForKids',\n",
       " 'attributes.GoodForMeal',\n",
       " 'attributes.HairSpecializesIn',\n",
       " 'attributes.HappyHour',\n",
       " 'attributes.HasTV',\n",
       " 'attributes.Music',\n",
       " 'attributes.NoiseLevel',\n",
       " 'attributes.Open24Hours',\n",
       " 'attributes.OutdoorSeating',\n",
       " 'attributes.RestaurantsAttire',\n",
       " 'attributes.RestaurantsCounterService',\n",
       " 'attributes.RestaurantsDelivery',\n",
       " 'attributes.RestaurantsGoodForGroups',\n",
       " 'attributes.RestaurantsPriceRange2',\n",
       " 'attributes.RestaurantsReservations',\n",
       " 'attributes.RestaurantsTableService',\n",
       " 'attributes.RestaurantsTakeOut',\n",
       " 'attributes.Smoking',\n",
       " 'attributes.WheelchairAccessible',\n",
       " 'attributes.WiFi',\n",
       " 'business_id',\n",
       " 'categories',\n",
       " 'city',\n",
       " 'hours',\n",
       " 'hours.Friday',\n",
       " 'hours.Monday',\n",
       " 'hours.Saturday',\n",
       " 'hours.Sunday',\n",
       " 'hours.Thursday',\n",
       " 'hours.Tuesday',\n",
       " 'hours.Wednesday',\n",
       " 'is_open',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'name',\n",
       " 'neighborhood',\n",
       " 'postal_code',\n",
       " 'review_count',\n",
       " 'stars',\n",
       " 'state'}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_path = '../data/json/yelp_academic_dataset_business.json'\n",
    "get_superset_of_column_names(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id',\n",
       " 'cool',\n",
       " 'date',\n",
       " 'funny',\n",
       " 'review_id',\n",
       " 'stars',\n",
       " 'text',\n",
       " 'useful',\n",
       " 'user_id'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_path = '../data/json/yelp_academic_dataset_review.json'\n",
    "get_superset_of_column_names(json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names(d, parent_key = ''):\n",
    "    '''\n",
    "    Arguments:\n",
    "    d : Nested dictionary of contents\n",
    "\n",
    "    Recursively extracts the keys of d and \n",
    "    returns a list of flattened keys as column_names\n",
    "\n",
    "    Return:\n",
    "    column_names : Flattened list of key names\n",
    "    \n",
    "    Example: \n",
    "    d = {'a' : {'b' : 0, 'c' : 1}}\n",
    "    column_names = ['a.b', 'a.c']\n",
    "    '''\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    for key, val in d.items():\n",
    "        column_name = f'{parent_key}.{key}' if parent_key else key\n",
    "        \n",
    "        # if val is a dictionary, recursively call get_column_names\n",
    "        if isinstance(val, collections.MutableMapping):\n",
    "            column_names.extend(get_column_names(val, column_name))\n",
    "        else:\n",
    "            column_names.append(column_name)\n",
    "            \n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a.b', 'a.c']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a' : {'b' : 0, 'c' : 1}}\n",
    "get_column_names(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Nested Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_value(d, key):\n",
    "    '''\n",
    "    Arguments: \n",
    "    d : Nested dictionary of contents\n",
    "    key : Flattened key string\n",
    "    \n",
    "    Recursively extracts the value from a nested dictionary given a key\n",
    "    \n",
    "    Return:\n",
    "    Value of d[key]\n",
    "    \n",
    "    Example:\n",
    "    d = {'a' : {'b' : 0, 'c' : 1}}\n",
    "    key = 'a.b'\n",
    "    value = 0\n",
    "    '''\n",
    "    \n",
    "    if d is None:\n",
    "        return None\n",
    "    \n",
    "    # check if key is an end node\n",
    "    if '.' not in key:\n",
    "        # return value = d[key] if it exists\n",
    "        if key not in d:\n",
    "            return None\n",
    "        return d[key]\n",
    "    \n",
    "    # extract parent key from child key(s)\n",
    "    parent_key, child_key = key.split('.', 1)\n",
    "    \n",
    "    if parent_key not in d:\n",
    "        return None\n",
    "    # get value of d[parent_key] is a dictionary for recursive call\n",
    "    child_d = d[parent_key]\n",
    "    \n",
    "    return get_nested_value(child_d, child_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a' : {'b' : 0, 'c' : 1}, 'd' : {'e' : None, 'f' : 2}}\n",
    "get_nested_value(d, 'd.f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row(d, column_names):\n",
    "    '''\n",
    "    Arguments:\n",
    "    d : Nested dictionary of contents\n",
    "    column_names : List of column names.\n",
    "        ** ASSUMES ALL column_names ARE VALID **\n",
    "     \n",
    "    Return:\n",
    "    row : List of values as strings\n",
    "    \n",
    "    Returns a csv compatible row given column names and a dict\n",
    "    '''\n",
    "    row = []    \n",
    "    for column_name in column_names:\n",
    "        val = get_nested_value(d, column_name)\n",
    "\n",
    "        if val is not None:\n",
    "            row.append(str(val))\n",
    "        else:\n",
    "            row.append('')\n",
    "\n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"{'b': 0, 'c': 'C'}\", '', '0', 'C', '']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a' : {'b' : 0, 'c' : 'C'}}\n",
    "get_row(d, ['a', 'b', 'a.b', 'a.c', 'a.d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSON to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'longitude', 'attributes.BYOB', 'attributes.Open24Hours', 'attributes.NoiseLevel', 'attributes.CoatCheck', 'attributes.BYOBCorkage', 'stars', 'attributes.HasTV', 'hours.Monday', 'attributes.BestNights', 'attributes.DriveThru', 'attributes.RestaurantsPriceRange2', 'attributes.RestaurantsTableService', 'review_count', 'business_id', 'attributes.RestaurantsCounterService', 'attributes.GoodForKids', 'attributes.RestaurantsGoodForGroups', 'state', 'attributes.Caters', 'attributes.Ambience', 'neighborhood', 'attributes.RestaurantsDelivery', 'address', 'attributes.WiFi', 'hours', 'attributes.HappyHour', 'attributes.RestaurantsAttire', 'attributes.OutdoorSeating', 'attributes.ByAppointmentOnly', 'attributes.Smoking', 'hours.Thursday', 'attributes.AcceptsInsurance', 'attributes.Alcohol', 'categories', 'attributes.Corkage', 'attributes.BusinessAcceptsCreditCards', 'attributes.BusinessParking', 'name', 'attributes.DogsAllowed', 'attributes.Music', 'attributes.GoodForMeal', 'hours.Friday', 'attributes.BusinessAcceptsBitcoin', 'hours.Tuesday', 'attributes.GoodForDancing', 'attributes.WheelchairAccessible', 'attributes', 'is_open', 'attributes.DietaryRestrictions', 'attributes.RestaurantsReservations', 'latitude', 'hours.Wednesday', 'postal_code', 'attributes.HairSpecializesIn', 'attributes.AgesAllowed', 'attributes.RestaurantsTakeOut', 'city', 'attributes.BikeParking', 'hours.Sunday', 'hours.Saturday'}\n",
      "25.145274877548218\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = json_file_paths['business']\n",
    "csv_file_path = csv_file_paths['business']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time.Mon-7', 'time.Thu-8', 'time.Tue-6', 'time.Sun-5', 'time.Mon-1', 'time.Sun-10', 'time.Tue-1', 'time.Sat-22', 'time.Fri-13', 'time.Sat-5', 'time.Fri-3', 'time.Fri-0', 'time.Fri-20', 'time.Sun-8', 'time.Tue-14', 'time.Sat-23', 'time.Fri-23', 'time.Thu-11', 'time.Sat-16', 'time.Tue-17', 'time.Tue-21', 'time.Wed-19', 'time.Wed-16', 'time.Tue-11', 'time.Sat-7', 'time.Mon-10', 'time.Sat-19', 'time.Mon-11', 'time.Sat-4', 'time.Thu-5', 'time.Wed-11', 'time.Thu-4', 'time.Sat-6', 'time.Sun-20', 'time.Sat-21', 'time.Thu-12', 'time.Sat-1', 'time.Sat-11', 'time.Thu-17', 'time.Mon-5', 'time.Mon-16', 'time.Fri-8', 'time.Tue-12', 'time.Mon-3', 'time.Thu-16', 'time.Tue-18', 'time.Tue-22', 'time.Sun-16', 'time.Sat-8', 'time.Tue-2', 'time.Wed-1', 'time.Fri-16', 'time.Mon-0', 'time.Wed-8', 'time.Thu-6', 'time.Thu-22', 'time.Mon-4', 'time.Sat-17', 'time.Mon-13', 'time.Fri-17', 'time.Mon-14', 'time.Sun-4', 'time.Thu-9', 'time.Sat-12', 'time.Thu-19', 'time.Sun-23', 'time.Sun-7', 'time.Sun-21', 'time.Thu-13', 'time.Mon-8', 'time.Fri-22', 'time.Fri-4', 'time.Fri-19', 'time.Tue-7', 'time.Sat-2', 'time.Tue-23', 'time.Thu-0', 'time.Sun-19', 'time.Sun-3', 'time.Sun-6', 'time.Sun-18', 'time.Thu-10', 'time.Sat-3', 'time.Fri-6', 'time.Fri-7', 'time.Sun-15', 'time.Mon-2', 'time.Wed-2', 'time.Thu-7', 'time.Wed-3', 'time.Tue-8', 'time.Sun-2', 'time.Thu-3', 'time.Mon-20', 'time.Fri-12', 'time.Thu-23', 'time.Sat-9', 'time.Sat-15', 'time.Sun-22', 'time.Sat-10', 'time.Sun-13', 'time.Tue-16', 'time.Sat-18', 'time.Wed-9', 'time.Sat-0', 'time.Sat-13', 'time.Thu-21', 'time.Sun-14', 'time.Wed-10', 'time.Tue-13', 'business_id', 'time.Wed-4', 'time.Wed-7', 'time.Thu-1', 'time.Fri-5', 'time.Wed-23', 'time.Mon-22', 'time.Wed-0', 'time.Tue-9', 'time.Sun-11', 'time.Fri-2', 'time.Mon-12', 'time.Thu-14', 'time.Fri-18', 'time.Mon-9', 'time.Mon-21', 'time.Mon-18', 'time.Wed-22', 'time.Sun-0', 'time.Thu-18', 'time.Tue-3', 'time.Thu-20', 'time.Mon-17', 'time.Sat-14', 'time.Thu-15', 'time.Fri-21', 'time.Wed-12', 'time.Sun-12', 'time.Wed-14', 'time.Wed-17', 'time.Mon-23', 'time.Wed-20', 'time.Wed-21', 'time.Fri-14', 'time.Fri-11', 'time.Tue-5', 'time.Mon-15', 'time.Mon-19', 'time.Wed-13', 'time.Fri-15', 'time.Wed-18', 'time.Fri-10', 'time.Fri-9', 'time.Wed-6', 'time.Sat-20', 'time.Wed-15', 'time.Fri-1', 'time.Mon-6', 'time.Tue-0', 'time.Tue-10', 'time.Sun-1', 'time.Tue-20', 'time.Tue-15', 'time.Thu-2', 'time.Tue-19', 'time.Tue-4', 'time.Sun-17', 'time.Sun-9', 'time.Wed-5'}\n",
      "32.837047815322876\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = json_file_paths['checkin']\n",
    "csv_file_path = csv_file_paths['checkin']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label', 'caption', 'photo_id', 'business_id'}\n",
      "5.052654027938843\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = json_file_paths['photo']\n",
    "csv_file_path = csv_file_paths['photo']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294.8083598613739\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = '../data/json/yelp_academic_dataset_review.json'\n",
    "csv_file_path = json_file_path.replace('json', 'csv')\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text', 'likes', 'date', 'business_id', 'user_id'}\n",
      "27.073715925216675\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = json_file_paths['tip']\n",
    "csv_file_path = csv_file_paths['tip']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name', 'elite', 'user_id', 'fans', 'average_stars', 'review_count', 'compliment_hot', 'compliment_writer', 'compliment_profile', 'compliment_note', 'compliment_cool', 'compliment_plain', 'useful', 'compliment_cute', 'yelping_since', 'friends', 'cool', 'compliment_photos', 'funny', 'compliment_more', 'compliment_funny', 'compliment_list'}\n",
      "143.07469487190247\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = json_file_paths['user']\n",
    "csv_file_path = csv_file_paths['user']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV\n",
    "\n",
    "Verify that JSON file was successfully converted to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(csv_file_paths['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>elite</th>\n",
       "      <th>user_id</th>\n",
       "      <th>fans</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>...</th>\n",
       "      <th>useful</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>friends</th>\n",
       "      <th>cool</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>funny</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Susan</td>\n",
       "      <td>None</td>\n",
       "      <td>lzlZwIpuSWXEnNS91wxjHw</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-28</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daipayan</td>\n",
       "      <td>None</td>\n",
       "      <td>XvLBr-9smbI0m_a7dXtB7w</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-05</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andy</td>\n",
       "      <td>None</td>\n",
       "      <td>QPT4Ud4H5sJVr68yXhoWFw</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jonathan</td>\n",
       "      <td>None</td>\n",
       "      <td>i5YitlHZpf0B3R0s_8NVuw</td>\n",
       "      <td>0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-08-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shashank</td>\n",
       "      <td>None</td>\n",
       "      <td>s4FoIXE_LSGviTHBe8dmcg</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-18</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name elite                 user_id  fans  average_stars  review_count  \\\n",
       "0     Susan  None  lzlZwIpuSWXEnNS91wxjHw     0           2.00             1   \n",
       "1  Daipayan  None  XvLBr-9smbI0m_a7dXtB7w     0           5.00             2   \n",
       "2      Andy  None  QPT4Ud4H5sJVr68yXhoWFw     0           4.00             1   \n",
       "3  Jonathan  None  i5YitlHZpf0B3R0s_8NVuw     0           4.05            19   \n",
       "4  Shashank  None  s4FoIXE_LSGviTHBe8dmcg     0           3.00             3   \n",
       "\n",
       "   compliment_hot  compliment_writer  compliment_profile  compliment_note  \\\n",
       "0               0                  0                   0                0   \n",
       "1               0                  0                   0                0   \n",
       "2               0                  0                   0                0   \n",
       "3               0                  0                   0                0   \n",
       "4               0                  0                   0                0   \n",
       "\n",
       "        ...         useful  compliment_cute  yelping_since  friends cool  \\\n",
       "0       ...              0                0     2015-09-28     None    0   \n",
       "1       ...              0                0     2015-09-05     None    0   \n",
       "2       ...              0                0     2016-07-21     None    0   \n",
       "3       ...              0                0     2014-08-04     None    0   \n",
       "4       ...              0                0     2017-06-18     None    0   \n",
       "\n",
       "  compliment_photos  funny  compliment_more  compliment_funny  compliment_list  \n",
       "0                 0      0                0                 0                0  \n",
       "1                 0      0                0                 0                0  \n",
       "2                 0      0                0                 0                0  \n",
       "3                 0      0                0                 0                0  \n",
       "4                 0      0                0                 0                0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1518169, 22)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
