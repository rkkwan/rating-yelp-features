{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_soup_reviews = pd.read_csv('../data/interim/onion_soup_reviews.csv')\n",
    "onion_soup_sentences = pd.read_csv('../data/interim/onion_soup_sentences.csv')\n",
    "menu = pd.read_csv('../data/interim/menu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>business_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other than being right across the Fountains of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>uczUlWIWuO-KzoUiLhICNw</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9zuYkm3k4_9KjE1PC8EPfg</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French onion soup was watery with little taste...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185E0cpQpDRUO4JRGu3fXQ</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EYiYLS0ZHDKGJSb1IKcpwg</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where to begin!  Now our dining experience her...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>QoY3L_d_axTcMn68pI8zxQ</td>\n",
       "      <td>2014-12-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mp3Xy-w2isyLjEN91xOeGQ</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charming resturant that looks like it would be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nth_q-GqOy_Ly8sxsREIwA</td>\n",
       "      <td>2010-12-04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M4g64KUEia1qgcn-qNlYsw</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This review is long overdue!   I have been eat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>l0Lm7Dx69s6aH7a-5dwKDg</td>\n",
       "      <td>2010-07-11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pQAUyBorkc1ZOxmV-uJ02w</td>\n",
       "      <td>Mon Ami Gabi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cool  funny  \\\n",
       "0  Other than being right across the Fountains of...   1.0    2.0   \n",
       "1  French onion soup was watery with little taste...   0.0    0.0   \n",
       "2  Where to begin!  Now our dining experience her...   0.0    0.0   \n",
       "3  Charming resturant that looks like it would be...   0.0    0.0   \n",
       "4  This review is long overdue!   I have been eat...   0.0    0.0   \n",
       "\n",
       "                review_id        date  stars             business_id  useful  \\\n",
       "0  uczUlWIWuO-KzoUiLhICNw  2015-02-10    2.0  4JNXUYY8wbaaDmk3BPzlWw     3.0   \n",
       "1  185E0cpQpDRUO4JRGu3fXQ  2017-04-24    3.0  4JNXUYY8wbaaDmk3BPzlWw     0.0   \n",
       "2  QoY3L_d_axTcMn68pI8zxQ  2014-12-03    5.0  4JNXUYY8wbaaDmk3BPzlWw     1.0   \n",
       "3  nth_q-GqOy_Ly8sxsREIwA  2010-12-04    4.0  4JNXUYY8wbaaDmk3BPzlWw     0.0   \n",
       "4  l0Lm7Dx69s6aH7a-5dwKDg  2010-07-11    5.0  4JNXUYY8wbaaDmk3BPzlWw     0.0   \n",
       "\n",
       "                  user_id business_name  \n",
       "0  9zuYkm3k4_9KjE1PC8EPfg  Mon Ami Gabi  \n",
       "1  EYiYLS0ZHDKGJSb1IKcpwg  Mon Ami Gabi  \n",
       "2  mp3Xy-w2isyLjEN91xOeGQ  Mon Ami Gabi  \n",
       "3  M4g64KUEia1qgcn-qNlYsw  Mon Ami Gabi  \n",
       "4  pQAUyBorkc1ZOxmV-uJ02w  Mon Ami Gabi  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our table ordered Bordelaise Steak Frites (...</td>\n",
       "      <td>scallops_gratinees, onion_soup_au_gratin, bord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The steak frites and onion soup were the be...</td>\n",
       "      <td>onion_soup_au_gratin, prime_steak_frites, frites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Onion soup was also a nice, big portion, but ...</td>\n",
       "      <td>onion_soup_au_gratin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French onion soup was watery with little taste</td>\n",
       "      <td>onion_soup_au_gratin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We ate almost everything on the menu - altho...</td>\n",
       "      <td>baked_goat_cheese, onion_soup_au_gratin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0     Our table ordered Bordelaise Steak Frites (...   \n",
       "1     The steak frites and onion soup were the be...   \n",
       "2   Onion soup was also a nice, big portion, but ...   \n",
       "3     French onion soup was watery with little taste   \n",
       "4    We ate almost everything on the menu - altho...   \n",
       "\n",
       "                                                tags  \n",
       "0  scallops_gratinees, onion_soup_au_gratin, bord...  \n",
       "1   onion_soup_au_gratin, prime_steak_frites, frites  \n",
       "2                               onion_soup_au_gratin  \n",
       "3                               onion_soup_au_gratin  \n",
       "4            baked_goat_cheese, onion_soup_au_gratin  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_term(word_list, term):\n",
    "    '''\n",
    "    Arguments:\n",
    "    word_list : List of words or a string\n",
    "    term      : List or string of words to search for\n",
    "    \n",
    "    Finds the start and end indices of a search term in a string.\n",
    "    `start` is the index of the first character in `term` in word_list,\n",
    "    `end` is the index of the last character in `term` in word_list.    \n",
    "    \n",
    "    Return:\n",
    "    results : List of tuples (start, end)\n",
    "    '''    \n",
    "    # Check if word_list is a string or list\n",
    "    if type(word_list) is str:\n",
    "        word_list = word_list.lower().split()\n",
    "    elif type(word_list) is not list:\n",
    "        print('Error: word_list must be a list or string.')\n",
    "        return None\n",
    "\n",
    "    # Check if term is a string or list    \n",
    "    if type(term) is str:\n",
    "        term = term.lower().split()\n",
    "    elif type(term) is not list:\n",
    "        print('Error: term must be a list or string.')\n",
    "        return None\n",
    "\n",
    "    results = []\n",
    "    term_length = len(term)\n",
    "\n",
    "    # Find indices of term[0] in sentence\n",
    "    for ind in (i for i, word in enumerate(word_list) if word == term[0]):\n",
    "        # Check if rest of the term matches\n",
    "        if word_list[ind:ind + term_length] == term:\n",
    "            results.append((ind, ind+term_length-1))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (8, 9)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_term('The onion soup is at index (1,2). The onion soup is also at index (8,9).', 'onion soup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(word_list, term, n_before = 5, n_after = 5):\n",
    "    '''\n",
    "    Arguments:\n",
    "    word_list : List or string of words\n",
    "    term      : List or string of words to search for\n",
    "    before    : Number of characters to span before term\n",
    "    after     : Number of characters to span after term   \n",
    "    \n",
    "    Gets a list of sentence fragments containing term in word_list\n",
    "    Each sentence fragment spans n_before characters to the left\n",
    "    or until the start of the word_list\n",
    "    and n_after characters to the right \n",
    "    or until the end of the word_list\n",
    "    \n",
    "    Return:\n",
    "    chunks : List of chunks\n",
    "    \n",
    "    '''\n",
    "    # Check if word_list is a string or list\n",
    "    if type(word_list) is str:\n",
    "        word_list = word_list.lower().split()\n",
    "    elif type(word_list) is not list:\n",
    "        print('Error: word_list must be a list or string.')\n",
    "        return None\n",
    "    \n",
    "    # Check if term is a string or list    \n",
    "    if type(term) is str:\n",
    "        term = term.lower().split()\n",
    "    elif type(term) is not list:\n",
    "        print('Error: term must be a list or string.')\n",
    "        return None    \n",
    "    \n",
    "    indices = find_term(word_list, term)\n",
    "    chunks = []\n",
    "\n",
    "    for start, end in indices:\n",
    "        before = n_before\n",
    "        after = n_after\n",
    "        \n",
    "        # Check if start index is near the beginning of the word_list\n",
    "        if start < n_before:\n",
    "            before = start\n",
    "        # Check if end index is near the end of the word_list\n",
    "        if end > len(word_list) - n_after:\n",
    "            after = len(word_list) - end\n",
    "            \n",
    "        chunks.append(' '.join(word_list[start-before : end+after+1]))\n",
    "        \n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my children do not like onion soup']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'I got the the onion soup, which was great my wife also enjoyed the onion soup, my children do not like onion soup'\n",
    "get_chunks(test, 'onion soup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input string must be lemmatized before running `get_chunks()`, or it will fail to extract terms with punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i got the the onion soup which was great my wife',\n",
       " 'my wife also enjoyed the onion soup my children do not like',\n",
       " 'my children do not like onion soup']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'I got the the onion soup which was great my wife also enjoyed the onion soup my children do not like onion soup'\n",
    "get_chunks(test, 'onion soup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(superlist): \n",
    "    '''\n",
    "    Arguments: \n",
    "    superlist : A list of list of strings.\n",
    "\n",
    "    Requirements: \n",
    "    Each element in superlist must be a list.\n",
    "    \n",
    "    Return:\n",
    "    A flattened list of strings.\n",
    "\n",
    "    ex: \n",
    "    flatten([['a'], ['b', 'c'], ['d', 'e', 'f']])\n",
    "    >> ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "    '''    \n",
    "    return [item \\\n",
    "            for sublist in superlist \\\n",
    "            for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onion_soup_chunks = []\n",
    "onion_soup_chunks = onion_soup_sentences.apply(lambda row: \n",
    "                                                    get_chunks(list(TextBlob(row['text'].lower()).words), row['target']), axis = 1)\n",
    "onion_soup_chunks = pd.Series(flatten(onion_soup_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_soup_chunks = pd.concat([onion_soup_sentences['target'], onion_soup_chunks], axis = 1)\n",
    "onion_soup_chunks.columns = ['target', 'text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scallops shrimp peas and cream onion soup and eggs benedict with canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the steak frites and onion soup were the best things we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>onion soup was also a nice big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>french onion soup was watery with little taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the menu although their french onion soup was n't spectacular their baked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        text\n",
       "0  scallops shrimp peas and cream onion soup and eggs benedict with canadian\n",
       "1  the steak frites and onion soup were the best things we                  \n",
       "2  onion soup was also a nice big                                           \n",
       "3  french onion soup was watery with little taste                           \n",
       "4  the menu although their french onion soup was n't spectacular their baked"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_soup_chunks[['text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_soup_chunks.to_csv('../data/interim/onion_soup_chunks.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
