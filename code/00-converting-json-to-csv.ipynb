{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file extracted from the Yelp dataset (`yelp_academic.tar`) is a typeless file (`yelp_dataset`). This is actually another tar file, so manually add the `.tar` extension and extract again to get to the true data files. \n",
    "\n",
    "The Yelp Dataset is a series of JSON files. I will convert the JSON files to CSVs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import simplejson as sjson\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON and CSV File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['business', 'checkin', 'photo', 'review', 'tip', 'user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_paths = {cat : f'../data/external/yelp_academic_dataset_{cat}.json'\n",
    "                   for cat in categories}\n",
    "\n",
    "csv_file_paths = {cat : f'../data/raw/yelp_academic_dataset_{cat}.csv'\n",
    "                   for cat in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': '../data/external/yelp_academic_dataset_business.json',\n",
       " 'checkin': '../data/external/yelp_academic_dataset_checkin.json',\n",
       " 'photo': '../data/external/yelp_academic_dataset_photo.json',\n",
       " 'review': '../data/external/yelp_academic_dataset_review.json',\n",
       " 'tip': '../data/external/yelp_academic_dataset_tip.json',\n",
       " 'user': '../data/external/yelp_academic_dataset_user.json'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': '../data/raw/yelp_academic_dataset_business.csv',\n",
       " 'checkin': '../data/raw/yelp_academic_dataset_checkin.csv',\n",
       " 'photo': '../data/raw/yelp_academic_dataset_photo.csv',\n",
       " 'review': '../data/raw/yelp_academic_dataset_review.csv',\n",
       " 'tip': '../data/raw/yelp_academic_dataset_tip.csv',\n",
       " 'user': '../data/raw/yelp_academic_dataset_user.csv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in JSON, Write out to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_write_file(json_file_path, csv_file_path, column_names):\n",
    "    '''\n",
    "    Arguments:\n",
    "    json_file_path (str) : pathname of a JSON file\n",
    "    csv_file_path (str) : pathname of CSV file\n",
    "    column_names (set) : column names (keys) of a JSON file\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \n",
    "    Read in JSON file\n",
    "    Write out as CSV file with column_names as header\n",
    "    '''\n",
    "    \n",
    "    with open(csv_file_path, 'w+') as f_out:\n",
    "        csv_file = csv.writer(f_out)\n",
    "        csv_file.writerow(list(column_names))\n",
    "        with open(json_file_path) as f_in:\n",
    "            for line in f_in:\n",
    "                d = sjson.loads(line)\n",
    "                csv_file.writerow(get_row(d, column_names))\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names(d, parent_key = ''):\n",
    "    '''\n",
    "    Arguments:\n",
    "    d (dict) : Nested dictionary of contents\n",
    "\n",
    "    Recursively extracts the keys of d and \n",
    "    returns a list of flattened keys as column_names\n",
    "\n",
    "    Returns:\n",
    "    column_names (list) : Flattened list of key names\n",
    "    \n",
    "    Example: \n",
    "    d = {'a' : {'b' : 0, 'c' : 1}}\n",
    "    column_names = ['a.b', 'a.c']\n",
    "    '''\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    for key, val in d.items():\n",
    "        column_name = f'{parent_key}.{key}' if parent_key else key\n",
    "        \n",
    "        # if val is a dictionary, recursively call get_column_names\n",
    "        if isinstance(val, collections.MutableMapping):\n",
    "            column_names.extend(get_column_names(val, column_name))\n",
    "        else:\n",
    "            column_names.append(column_name)\n",
    "            \n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a.b', 'a.c']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a' : {'b' : 0, 'c' : 1}}\n",
    "get_column_names(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Nested Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_value(d, key):\n",
    "    '''\n",
    "    Arguments: \n",
    "    d (dict) : Nested dictionary of contents\n",
    "    key (str) : Flattened key string\n",
    "    \n",
    "    Recursively extracts the value from a nested dictionary given a key\n",
    "    \n",
    "    Returns:\n",
    "    Value of d[key]\n",
    "    \n",
    "    Example:\n",
    "    d = {'a' : {'b' : 0, 'c' : 1}}\n",
    "    key = 'a.b'\n",
    "    value = 0\n",
    "    '''\n",
    "    \n",
    "    if d is None:\n",
    "        return None\n",
    "    \n",
    "    # check if key is an end node\n",
    "    if '.' not in key:\n",
    "        # return value = d[key] if it exists\n",
    "        if key not in d:\n",
    "            return None\n",
    "        return d[key]\n",
    "    \n",
    "    # extract parent key from child key(s)\n",
    "    parent_key, child_key = key.split('.', 1)\n",
    "    \n",
    "    if parent_key not in d:\n",
    "        return None\n",
    "    # get value of d[parent_key] is a dictionary for recursive call\n",
    "    child_d = d[parent_key]\n",
    "    \n",
    "    return get_nested_value(child_d, child_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a' : {'b' : 0, 'c' : 1}, 'd' : {'e' : None, 'f' : 2}}\n",
    "get_nested_value(d, 'd.f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row(d, column_names):\n",
    "    '''\n",
    "    Arguments:\n",
    "    d : Nested dictionary of contents\n",
    "    column_names : List of column names. ** ASSUMES ALL column_names ARE VALID **\n",
    "     \n",
    "    Returns:\n",
    "    row (list) : Values as strings\n",
    "    \n",
    "    Returns a csv compatible row given column names and a dict\n",
    "    '''\n",
    "    row = []    \n",
    "    for column_name in column_names:\n",
    "        val = get_nested_value(d, column_name)\n",
    "\n",
    "        if val is not None:\n",
    "            row.append(str(val))\n",
    "        else:\n",
    "            row.append('')\n",
    "\n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"{'b': 0, 'c': 'C'}\", '', '0', 'C', '']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a' : {'b' : 0, 'c' : 'C'}}\n",
    "get_row(d, ['a', 'b', 'a.b', 'a.c', 'a.d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Superset of Column Names\n",
    "The superset is the set of all possible column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superset_of_column_names(json_file_path):\n",
    "    '''\n",
    "    Arguments:\n",
    "    json_file_path (str) : pathname of a JSON file\n",
    "    \n",
    "    Extracts the unique column names (keys) of a JSON file\n",
    "    \n",
    "    Returns:\n",
    "    column_names (set) : Column names (keys) of a JSON file\n",
    "    \n",
    "    Example:\n",
    "    json_file = {'a' : {'b' : 1, 'c' : 2}}\n",
    "    column_names = {'a.b', 'a.c'}\n",
    "    '''\n",
    "    \n",
    "    column_names = set()\n",
    "    with open(json_file_path) as f_in:\n",
    "        for line in f_in:\n",
    "            d = sjson.loads(line)\n",
    "            column_names.update(set(get_column_names(d)))\n",
    "\n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attributes.WiFi', 'hours.Monday', 'attributes.RestaurantsPriceRange2', 'hours.Sunday', 'attributes.CoatCheck', 'attributes.RestaurantsGoodForGroups', 'neighborhood', 'attributes.DriveThru', 'city', 'attributes.NoiseLevel', 'address', 'attributes.BestNights', 'attributes.GoodForKids', 'attributes.GoodForMeal', 'attributes.ByAppointmentOnly', 'attributes.Open24Hours', 'attributes.RestaurantsTakeOut', 'postal_code', 'hours.Friday', 'attributes.BusinessAcceptsBitcoin', 'attributes.RestaurantsReservations', 'business_id', 'hours.Wednesday', 'attributes.RestaurantsCounterService', 'attributes.HappyHour', 'attributes.HairSpecializesIn', 'attributes.GoodForDancing', 'attributes.AgesAllowed', 'attributes.Caters', 'is_open', 'attributes', 'categories', 'attributes.RestaurantsDelivery', 'attributes.Alcohol', 'latitude', 'hours.Saturday', 'attributes.DietaryRestrictions', 'attributes.DogsAllowed', 'attributes.Smoking', 'attributes.Ambience', 'attributes.AcceptsInsurance', 'attributes.BYOB', 'state', 'attributes.BusinessParking', 'attributes.BYOBCorkage', 'attributes.RestaurantsTableService', 'attributes.BusinessAcceptsCreditCards', 'longitude', 'hours.Tuesday', 'hours', 'attributes.HasTV', 'stars', 'attributes.RestaurantsAttire', 'hours.Thursday', 'attributes.Music', 'review_count', 'attributes.BikeParking', 'name', 'attributes.OutdoorSeating', 'attributes.WheelchairAccessible', 'attributes.Corkage'}\n",
      "CPU times: user 8.97 s, sys: 69.7 ms, total: 9.04 s\n",
      "Wall time: 9.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "json_file_path = '../data/external/yelp_academic_dataset_business.json'\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text', 'user_id', 'useful', 'business_id', 'date', 'stars', 'review_id', 'funny', 'cool'}\n",
      "CPU times: user 1min 52s, sys: 1.58 s, total: 1min 53s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "json_file_path = '../data/external/yelp_academic_dataset_review.json'\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSON to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attributes.WiFi', 'hours.Monday', 'attributes.RestaurantsPriceRange2', 'hours.Sunday', 'attributes.CoatCheck', 'attributes.RestaurantsGoodForGroups', 'neighborhood', 'attributes.DriveThru', 'city', 'attributes.NoiseLevel', 'address', 'attributes.BestNights', 'attributes.GoodForKids', 'attributes.GoodForMeal', 'attributes.ByAppointmentOnly', 'attributes.Open24Hours', 'attributes.RestaurantsTakeOut', 'postal_code', 'hours.Friday', 'attributes.BusinessAcceptsBitcoin', 'attributes.RestaurantsReservations', 'business_id', 'hours.Wednesday', 'attributes.RestaurantsCounterService', 'attributes.HappyHour', 'attributes.HairSpecializesIn', 'attributes.GoodForDancing', 'attributes.AgesAllowed', 'attributes.Caters', 'is_open', 'attributes', 'categories', 'attributes.RestaurantsDelivery', 'attributes.Alcohol', 'latitude', 'hours.Saturday', 'attributes.DietaryRestrictions', 'attributes.DogsAllowed', 'attributes.Smoking', 'attributes.Ambience', 'attributes.AcceptsInsurance', 'attributes.BYOB', 'state', 'attributes.BusinessParking', 'attributes.BYOBCorkage', 'attributes.RestaurantsTableService', 'attributes.BusinessAcceptsCreditCards', 'longitude', 'hours.Tuesday', 'hours', 'attributes.HasTV', 'stars', 'attributes.RestaurantsAttire', 'hours.Thursday', 'attributes.Music', 'review_count', 'attributes.BikeParking', 'name', 'attributes.OutdoorSeating', 'attributes.WheelchairAccessible', 'attributes.Corkage'}\n",
      "CPU times: user 24.7 s, sys: 435 ms, total: 25.1 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "json_file_path = json_file_paths['business']\n",
    "csv_file_path = csv_file_paths['business']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time.Sun-6', 'time.Sat-21', 'time.Fri-5', 'time.Sat-4', 'time.Tue-8', 'time.Sat-13', 'time.Mon-13', 'time.Sat-8', 'time.Wed-22', 'time.Sat-3', 'time.Wed-21', 'time.Tue-13', 'time.Mon-22', 'time.Mon-15', 'time.Tue-18', 'time.Sat-10', 'time.Sun-9', 'time.Wed-18', 'time.Tue-23', 'time.Mon-16', 'time.Sun-23', 'time.Wed-8', 'time.Mon-11', 'time.Mon-12', 'time.Thu-15', 'time.Fri-18', 'time.Tue-17', 'time.Tue-14', 'time.Mon-5', 'time.Sat-23', 'time.Wed-16', 'time.Fri-23', 'time.Sun-12', 'time.Thu-18', 'time.Thu-22', 'time.Tue-4', 'time.Sun-4', 'time.Thu-6', 'time.Sun-22', 'time.Sat-6', 'time.Mon-19', 'time.Mon-23', 'time.Thu-1', 'time.Thu-23', 'time.Mon-3', 'time.Wed-12', 'time.Mon-10', 'time.Wed-13', 'time.Fri-22', 'time.Wed-15', 'time.Fri-17', 'time.Fri-20', 'time.Fri-13', 'time.Mon-0', 'time.Sun-11', 'time.Thu-3', 'time.Sun-20', 'time.Sat-20', 'time.Sat-5', 'time.Mon-9', 'time.Thu-16', 'time.Wed-20', 'time.Tue-0', 'time.Tue-21', 'time.Wed-11', 'time.Sun-17', 'time.Thu-20', 'time.Fri-9', 'time.Thu-8', 'time.Sun-2', 'time.Sat-11', 'time.Mon-17', 'time.Fri-6', 'time.Fri-7', 'time.Sun-8', 'time.Thu-14', 'time.Wed-5', 'time.Thu-21', 'time.Mon-1', 'time.Thu-13', 'time.Sun-18', 'time.Sat-9', 'time.Sat-1', 'time.Thu-2', 'time.Fri-2', 'time.Tue-7', 'time.Sat-22', 'time.Tue-12', 'time.Sun-15', 'time.Wed-3', 'time.Fri-1', 'time.Thu-19', 'time.Fri-14', 'time.Tue-6', 'time.Wed-14', 'time.Sun-19', 'time.Wed-17', 'time.Sat-19', 'time.Thu-10', 'time.Tue-9', 'time.Tue-15', 'time.Wed-10', 'time.Fri-16', 'time.Thu-12', 'time.Sun-16', 'time.Mon-6', 'time.Sun-3', 'time.Sat-15', 'time.Mon-14', 'time.Tue-19', 'business_id', 'time.Sun-14', 'time.Fri-11', 'time.Wed-23', 'time.Mon-4', 'time.Fri-21', 'time.Mon-2', 'time.Thu-17', 'time.Fri-15', 'time.Sun-0', 'time.Fri-8', 'time.Thu-5', 'time.Thu-0', 'time.Sat-12', 'time.Wed-0', 'time.Fri-10', 'time.Sun-21', 'time.Tue-20', 'time.Fri-19', 'time.Sun-7', 'time.Wed-9', 'time.Thu-7', 'time.Mon-20', 'time.Mon-18', 'time.Mon-21', 'time.Sat-7', 'time.Tue-1', 'time.Wed-1', 'time.Wed-7', 'time.Mon-8', 'time.Tue-5', 'time.Thu-11', 'time.Fri-4', 'time.Sun-10', 'time.Fri-12', 'time.Sun-13', 'time.Mon-7', 'time.Wed-6', 'time.Fri-3', 'time.Tue-3', 'time.Sat-16', 'time.Sat-18', 'time.Sun-5', 'time.Wed-2', 'time.Fri-0', 'time.Thu-4', 'time.Tue-22', 'time.Tue-16', 'time.Tue-11', 'time.Sat-17', 'time.Sat-0', 'time.Wed-19', 'time.Wed-4', 'time.Tue-10', 'time.Tue-2', 'time.Sat-2', 'time.Thu-9', 'time.Sun-1', 'time.Sat-14'}\n",
      "CPU times: user 33 s, sys: 425 ms, total: 33.4 s\n",
      "Wall time: 34.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "json_file_path = json_file_paths['checkin']\n",
    "csv_file_path = csv_file_paths['checkin']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'photo_id', 'business_id', 'caption', 'label'}\n",
      "5.322238922119141\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = json_file_paths['photo']\n",
    "csv_file_path = csv_file_paths['photo']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306.009996175766\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = '../data/external/yelp_academic_dataset_review.json'\n",
    "csv_file_path = json_file_path.replace('json', 'csv')\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text', 'likes', 'user_id', 'date', 'business_id'}\n",
      "28.98428988456726\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = json_file_paths['tip']\n",
    "csv_file_path = csv_file_paths['tip']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compliment_profile', 'yelping_since', 'compliment_plain', 'compliment_photos', 'compliment_writer', 'compliment_list', 'compliment_note', 'useful', 'compliment_cute', 'friends', 'compliment_funny', 'compliment_more', 'average_stars', 'user_id', 'fans', 'compliment_cool', 'review_count', 'name', 'compliment_hot', 'funny', 'cool', 'elite'}\n",
      "151.38960790634155\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "json_file_path = json_file_paths['user']\n",
    "csv_file_path = csv_file_paths['user']\n",
    "\n",
    "column_names = get_superset_of_column_names(json_file_path)\n",
    "print(column_names)\n",
    "\n",
    "read_and_write_file(json_file_path, csv_file_path, column_names)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV\n",
    "\n",
    "Verify that JSON file was successfully converted to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(csv_file_paths['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>useful</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>friends</th>\n",
       "      <th>...</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>user_id</th>\n",
       "      <th>fans</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>review_count</th>\n",
       "      <th>name</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>lzlZwIpuSWXEnNS91wxjHw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Susan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>XvLBr-9smbI0m_a7dXtB7w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Daipayan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>QPT4Ud4H5sJVr68yXhoWFw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Andy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-08-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>4.05</td>\n",
       "      <td>i5YitlHZpf0B3R0s_8NVuw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>s4FoIXE_LSGviTHBe8dmcg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Shashank</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   compliment_profile yelping_since  compliment_plain  compliment_photos  \\\n",
       "0                   0    2015-09-28                 0                  0   \n",
       "1                   0    2015-09-05                 0                  0   \n",
       "2                   0    2016-07-21                 0                  0   \n",
       "3                   0    2014-08-04                 0                  0   \n",
       "4                   0    2017-06-18                 0                  0   \n",
       "\n",
       "   compliment_writer  compliment_list  compliment_note  useful  \\\n",
       "0                  0                0                0       0   \n",
       "1                  0                0                0       0   \n",
       "2                  0                0                0       0   \n",
       "3                  0                0                0       0   \n",
       "4                  0                0                0       0   \n",
       "\n",
       "   compliment_cute friends  ...    average_stars                 user_id  \\\n",
       "0                0    None  ...             2.00  lzlZwIpuSWXEnNS91wxjHw   \n",
       "1                0    None  ...             5.00  XvLBr-9smbI0m_a7dXtB7w   \n",
       "2                0    None  ...             4.00  QPT4Ud4H5sJVr68yXhoWFw   \n",
       "3                0    None  ...             4.05  i5YitlHZpf0B3R0s_8NVuw   \n",
       "4                0    None  ...             3.00  s4FoIXE_LSGviTHBe8dmcg   \n",
       "\n",
       "   fans compliment_cool  review_count      name  compliment_hot funny  cool  \\\n",
       "0     0               0             1     Susan               0     0     0   \n",
       "1     0               0             2  Daipayan               0     0     0   \n",
       "2     0               0             1      Andy               0     0     0   \n",
       "3     0               0            19  Jonathan               0     0     0   \n",
       "4     0               0             3  Shashank               0     0     0   \n",
       "\n",
       "   elite  \n",
       "0   None  \n",
       "1   None  \n",
       "2   None  \n",
       "3   None  \n",
       "4   None  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1518169, 22)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
