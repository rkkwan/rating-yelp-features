{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/28/2019\n",
    "\n",
    "- Reorganized project structure:\n",
    "```\n",
    "├──data/\n",
    "├────external/\n",
    "├────interim/\n",
    "├────processed/\n",
    "├────raw/\n",
    "├──logs/\n",
    "├──models/\n",
    "├──notebooks/\n",
    "├──reports/\n",
    "```\n",
    "\n",
    "- [Subsetting-Data](../notebooks/1.2-Subsetting-Data.ipynb)  \n",
    "    - timing\n",
    "        - `search_reviews()` function takes 63 seconds to run  \n",
    "        - Iterative masking takes 0.47 seconds  \n",
    "        - Supermasking (check all conditions at once) takes 2.12 seconds\n",
    "- Made subset data of Mon Ami Gabi, onion soup, eggs benedict\n",
    "- Uploaded Mon Ami Gabi reviews to Postgres\n",
    "- Tokenized and Lemmatized data\n",
    "- Handmade menu for Mon Ami Gabi\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/29/2019\n",
    "\n",
    "- Used `nltk`'s VADER SentimentIntensityAnalysis to perform **Sentence-level** Sentiment Analysis. There seems to be a lot of neutral scores (`compound`=0).\n",
    "- Review-level sentiment scores are inflated. Heavily skewed towards 1.\n",
    "- Sentence-level sentiment scores are more interesting.\n",
    "- **Entity-level** Sentiment Analysis may require hand-classifying the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/30/2019\n",
    "\n",
    "- Trying out [Spacy](https://spacy.io/usage/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/31/2019\n",
    "\n",
    "- Spacy\n",
    "- BlobText\n",
    "- BERT?\n",
    "- Milestone 3 1-on-1 with Mark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/1/2019\n",
    "\n",
    "- Try: For each sentence, find the index of `onion soup`, look `n` (3? 4? 5?) spaces before and after, and make that your sentence. \n",
    "- Try: sentiment analysis with NLTK, Spacy, BlobText, compare results. Maybe use all of them in a Vote.\n",
    "    - Result: They seem to be using the same sentiment algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/2/2019\n",
    "- Try: Weighted Mean of sentiment scores. Reviews with higher 'Useful' scores have higher weight.\n",
    "\n",
    "1. Got Sentiment score of each line\n",
    "2. Converted to stars rating\n",
    "3. Used mean of stars ratings as final prediction.\n",
    "\n",
    "#### Without dropping `compound=0` rows:  \n",
    "Review-level Rating: 4.8  \n",
    "Sentence-level Rating: 4.0  \n",
    "Entity-level Rating: 3.6\n",
    "\n",
    "#### Dropped `compound=0` rows:\n",
    "Review-level Rating: 4.8  \n",
    "Sentence-level Rating: 4.3  \n",
    "Entity-level Rating: 4.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/3/2019\n",
    "\n",
    "#### Chunking Algorithm\n",
    "- Currently taking (at most) 5 words before and 5 words after each sentence. Slicing is stopped early for start/end of sentence.\n",
    "- Try: Take n words before and after _until_ another noun chunk. \n",
    "\n",
    "\n",
    "#### Ranking Algorithm\n",
    "- Weighted mean, reviews with higher `useful` score get higher weight\n",
    "- Sorting\n",
    "    - Sentiment Score: Foods with highest sentiment scores get shown first\n",
    "    - Number of mention: Foods most mentioned in reviews get shown first\n",
    "    - \"Yelp Sort\": A combination of sentiment score and mentions    \n",
    "- Apply Bayesian Stats\n",
    "    - Prior : Sample size of the Mean, Mode? of the # of mentions of all food items\n",
    "        - sample size: Try \n",
    "            1. Static size, 30?\n",
    "            2. Relative size to individual restaurant?\n",
    "    - Observed : Actual mentions\n",
    "    - Check with Matt Brems\n",
    "        - Start with _one_ prior for all restaurants, then one prior per city\n",
    "- Take mean of Composite scores, THEN transform to Stars. Minimize artificial stats.\\\n",
    "\n",
    "#### Scaling up\n",
    "- All menu items in one restaurant\n",
    "- All restaurants\n",
    "\n",
    "#### Collecting more data\n",
    "- Yelp API?\n",
    "- Only look at reviews written by Yelp Elites\n",
    "\n",
    "#### Tuning Sentiment Analysis\n",
    "- Retrain Vader??\n",
    "    - \"To die for\", \"The BOMB\" are currently negative sentiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/4/2019\n",
    "\n",
    "#### Tasks:\n",
    "- Apply Bayesian\n",
    "- Tune 5-star rating\n",
    "- Scale to Big Data\n",
    "- Presentation 1\n",
    "    - Audience: Non-technical recruiter\n",
    "    - Prepare for technical questions anyway\n",
    "- Presentation 2\n",
    "    - Audience: Technical recruiter, senior data scientist\n",
    "    - Fully technical.\n",
    "- Retrain sentiment analyzer\n",
    "\n",
    "- [HTTrack](https://www.httrack.com/)\n",
    "    - Borrow a kind soul's front end\n",
    "    \n",
    "    \n",
    "- Search best \"Fried chicken\" in <area>,\n",
    "    - Return list of restaurants that have fried chicken, sorted by highest sentiment score / stars.\n",
    "    - Q: Would this still apply Bayesian stats? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/7/2019\n",
    "- Able to extract sentence fragments for each menu item. \n",
    "- Current bottleneck is splitting reviews to chunks for each menu item. Consider using a smaller menu to reduce processing time. \n",
    "    - Took `10m12s` for 7968 reviews and menu with 91 items\n",
    "    - Improve `get_chunks()`. Need to remove all punctuations before extracting sentence fragments. \"The onion soup, was ok.\" does not get extracted because of the comma, but it does get detected by .str.contains('onion soup).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/8/2019\n",
    "\n",
    "**Done**\n",
    "- Item-level sentiment analysis for all dishes at one restaurant.\n",
    "\n",
    "**To-Do**\n",
    "- Implement UC2. \n",
    "- Load data to Postgres.\n",
    "- Re-run sentiment analysis at the sentence-level.\n",
    "- Document all tools used in project. `odo`, `nltk`, `spacy`, `language`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "- Only detects sentiment of food item if it was in the same sentence. \n",
    "    - \"I got the fried chicken. It was great.\" does not get processed.\n",
    "- Vader's SIA is not ideal for review language.\n",
    "    - Vader interprets \"to die for\" and \"was the BOMB\" as highly negative (-0.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Forward\n",
    "\n",
    "### Apply Bayesian statistics\n",
    "\n",
    "### Implement UC2\n",
    "\n",
    "### Load data to Postgres\n",
    "\n",
    "\n",
    "\n",
    "### Train Custom Sentiment Analyzer for reviews\n",
    "- \"to die for\", \"was the bomb\" are currently very negative sentiments (`composite=-.6`)\n",
    "\n",
    "### Website: besteats.com\n",
    "\n",
    "1. **What should I order?**  \n",
    "    a.  User inputs a Yelp restaurant URL  \n",
    "    b.  Return a list of food items, sorted by highest sentiment. \n",
    "\n",
    "    \n",
    "2. **Where is the best `food_item` in town?**  \n",
    "    a. User inputs a food item and a region / city  \n",
    "    b. Return a list of restaurants that serve `food_item`, sorted by highest sentiment.\n",
    "\n",
    "\n",
    "- AB testing\n",
    "    - stars vs forks\n",
    "- User feedback\n",
    "    - accurate vs inaccurate\n",
    "\n",
    "### Collecting more data:\n",
    "- Reviews from other review websites: TripAdvisor, Eater, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
